import requests
import logging
from typing import Dict, List, Any, Optional
import re
import json
from datetime import datetime, timedelta
import sqlite3
from cachetools import TTLCache
import hashlib

logger = logging.getLogger(__name__)

class VulnerabilityCorrelator:
    def __init__(self):
        self.cve_cache = TTLCache(maxsize=1000, ttl=3600)  # Cache for 1 hour
        self.tech_patterns = {
            'apache': [r'apache[/\s](\d+\.\d+\.\d+)', r'server:\s*apache[/\s](\d+\.\d+\.\d+)'],
            'nginx': [r'nginx[/\s](\d+\.\d+\.\d+)', r'server:\s*nginx[/\s](\d+\.\d+\.\d+)'],
            'php': [r'php[/\s](\d+\.\d+\.\d+)', r'x-powered-by:\s*php[/\s](\d+\.\d+\.\d+)'],
            'mysql': [r'mysql[/\s](\d+\.\d+\.\d+)'],
            'wordpress': [r'wp-content', r'wordpress', r'/wp-admin/'],
            'drupal': [r'drupal', r'/sites/default/', r'drupal\.js'],
            'joomla': [r'joomla', r'/administrator/', r'joomla\.js'],
            'iis': [r'microsoft-iis[/\s](\d+\.\d+)', r'server:\s*microsoft-iis[/\s](\d+\.\d+)'],
            'tomcat': [r'tomcat[/\s](\d+\.\d+\.\d+)'],
            'jenkins': [r'jenkins[/\s](\d+\.\d+\.\d+)', r'x-jenkins'],
            'elasticsearch': [r'elasticsearch[/\s](\d+\.\d+\.\d+)'],
            'mongodb': [r'mongodb[/\s](\d+\.\d+\.\d+)'],
            'redis': [r'redis[/\s](\d+\.\d+\.\d+)'],
            'docker': [r'docker[/\s](\d+\.\d+\.\d+)'],
            'kubernetes': [r'kubernetes[/\s](\d+\.\d+\.\d+)']
        }
        
        self.port_services = {
            21: 'ftp',
            22: 'ssh',
            23: 'telnet',
            25: 'smtp',
            53: 'dns',
            80: 'http',
            110: 'pop3',
            143: 'imap',
            443: 'https',
            993: 'imaps',
            995: 'pop3s',
            1433: 'mssql',
            3306: 'mysql',
            3389: 'rdp',
            5432: 'postgresql',
            6379: 'redis',
            8080: 'http-alt',
            8443: 'https-alt',
            9200: 'elasticsearch',
            27017: 'mongodb'
        }
        
        # Initialize vulnerability database
        self.init_vuln_db()
    
    def init_vuln_db(self):
        """Initialize local vulnerability database."""
        try:
            conn = sqlite3.connect('vulnerabilities.db')
            cursor = conn.cursor()
            
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS cve_data (
                    cve_id TEXT PRIMARY KEY,
                    description TEXT,
                    cvss_score REAL,
                    severity TEXT,
                    published_date TEXT,
                    affected_products TEXT,
                    cve_references TEXT,
                    last_updated TEXT
                )
            ''')
            
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS vulnerability_scans (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    domain TEXT NOT NULL,
                    scan_timestamp TEXT NOT NULL,
                    technologies TEXT,
                    vulnerabilities TEXT,
                    risk_score INTEGER
                )
            ''')
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"Error initializing vulnerability database: {str(e)}")
    
    def correlate_vulnerabilities(self, domain_data: dict) -> dict:
        """Correlate discovered technologies with known vulnerabilities."""
        try:
            # Extract technologies and versions
            tech_stack = self.extract_tech_stack(domain_data)
            
            # Find vulnerabilities for each technology
            vulnerabilities = []
            total_cvss = 0
            critical_count = 0
            high_count = 0
            medium_count = 0
            low_count = 0
            
            for tech in tech_stack:
                tech_vulns = self.find_vulnerabilities_for_tech(tech)
                vulnerabilities.extend(tech_vulns)
                
                # Count by severity
                for vuln in tech_vulns:
                    cvss = vuln.get('cvss_score', 0)
                    total_cvss += cvss
                    
                    if cvss >= 9.0:
                        critical_count += 1
                    elif cvss >= 7.0:
                        high_count += 1
                    elif cvss >= 4.0:
                        medium_count += 1
                    else:
                        low_count += 1
            
            # Calculate overall risk score
            risk_score = self.calculate_risk_score(vulnerabilities, tech_stack)
            
            # Prioritize vulnerabilities
            prioritized_vulns = self.prioritize_vulnerabilities(vulnerabilities)
            
            # Generate recommendations
            recommendations = self.generate_vuln_recommendations(prioritized_vulns, tech_stack)
            
            result = {
                'domain': domain_data.get('domain', ''),
                'scan_timestamp': datetime.now().isoformat(),
                'tech_stack': tech_stack,
                'vulnerability_summary': {
                    'total_vulnerabilities': len(vulnerabilities),
                    'critical': critical_count,
                    'high': high_count,
                    'medium': medium_count,
                    'low': low_count,
                    'average_cvss': round(total_cvss / max(len(vulnerabilities), 1), 2)
                },
                'risk_score': risk_score,
                'prioritized_vulnerabilities': prioritized_vulns[:20],  # Top 20
                'recommendations': recommendations,
                'exploit_likelihood': self.assess_exploit_likelihood(prioritized_vulns),
                'compliance_impact': self.assess_compliance_impact(prioritized_vulns)
            }
            
            # Store scan results
            self.store_scan_results(result)
            
            return result
            
        except Exception as e:
            logger.error(f"Error correlating vulnerabilities: {str(e)}")
            return {
                'domain': domain_data.get('domain', ''),
                'error': str(e),
                'vulnerability_summary': {'total_vulnerabilities': 0}
            }
    
    def extract_tech_stack(self, domain_data: dict) -> List[dict]:
        """Extract technology stack from domain data."""
        tech_stack = []
        
        try:
            # From HTTP headers
            domain_status = domain_data.get('domain_status', {})
            if domain_status.get('active'):
                # Server header analysis
                technologies = domain_data.get('technologies', [])
                for tech in technologies:
                    tech_info = self.parse_technology_string(tech)
                    if tech_info:
                        tech_stack.append(tech_info)
            
            # From open ports
            open_ports = domain_data.get('open_ports', [])
            for port_info in open_ports:
                port = port_info.get('port')
                service = port_info.get('service', self.port_services.get(port, 'unknown'))
                
                tech_stack.append({
                    'name': service,
                    'version': 'unknown',
                    'type': 'service',
                    'port': port,
                    'confidence': 'medium'
                })
            
            # From SSL certificate
            ssl_data = domain_data.get('ssl', {})
            if ssl_data.get('valid'):
                issuer = ssl_data.get('issuer', '')
                if issuer and issuer != 'N/A':
                    tech_stack.append({
                        'name': 'ssl_certificate',
                        'version': 'unknown',
                        'type': 'security',
                        'issuer': issuer,
                        'confidence': 'high'
                    })
            
            # From DNS records (mail servers, etc.)
            dns_records = domain_data.get('dns', [])
            mx_records = [r for r in dns_records if r.get('type') == 'MX']
            if mx_records:
                tech_stack.append({
                    'name': 'mail_server',
                    'version': 'unknown',
                    'type': 'service',
                    'confidence': 'medium'
                })
            
            # Deduplicate and enhance
            tech_stack = self.deduplicate_tech_stack(tech_stack)
            
            return tech_stack
            
        except Exception as e:
            logger.error(f"Error extracting tech stack: {str(e)}")
            return []
    
    def parse_technology_string(self, tech_string: str) -> Optional[dict]:
        """Parse technology string to extract name and version."""
        try:
            tech_lower = tech_string.lower()
            
            for tech_name, patterns in self.tech_patterns.items():
                for pattern in patterns:
                    match = re.search(pattern, tech_lower)
                    if match:
                        version = match.group(1) if match.groups() else 'unknown'
                        return {
                            'name': tech_name,
                            'version': version,
                            'type': 'software',
                            'confidence': 'high',
                            'raw_string': tech_string
                        }
            
            # Generic parsing for unknown technologies
            version_match = re.search(r'(\d+\.\d+(?:\.\d+)?)', tech_string)
            if version_match:
                return {
                    'name': re.sub(r'[/\s]\d+.*', '', tech_string).lower(),
                    'version': version_match.group(1),
                    'type': 'software',
                    'confidence': 'medium',
                    'raw_string': tech_string
                }
            
            return None
            
        except Exception as e:
            logger.error(f"Error parsing technology string: {str(e)}")
            return None
    
    def find_vulnerabilities_for_tech(self, tech: dict) -> List[dict]:
        """Find vulnerabilities for a specific technology."""
        try:
            tech_name = tech['name']
            tech_version = tech.get('version', 'unknown')
            
            # Check cache first
            cache_key = f"{tech_name}_{tech_version}"
            if cache_key in self.cve_cache:
                return self.cve_cache[cache_key]
            
            vulnerabilities = []
            
            # Query NIST NVD API
            nvd_vulns = self.query_nvd_api(tech_name, tech_version)
            vulnerabilities.extend(nvd_vulns)
            
            # Query local vulnerability database
            local_vulns = self.query_local_vuln_db(tech_name, tech_version)
            vulnerabilities.extend(local_vulns)
            
            # Add known vulnerabilities for specific technologies
            known_vulns = self.get_known_vulnerabilities(tech_name, tech_version)
            vulnerabilities.extend(known_vulns)
            
            # Deduplicate
            seen_cves = set()
            unique_vulns = []
            for vuln in vulnerabilities:
                cve_id = vuln.get('cve_id', '')
                if cve_id and cve_id not in seen_cves:
                    seen_cves.add(cve_id)
                    unique_vulns.append(vuln)
            
            # Cache results
            self.cve_cache[cache_key] = unique_vulns
            
            return unique_vulns
            
        except Exception as e:
            logger.error(f"Error finding vulnerabilities for {tech}: {str(e)}")
            return []
    
    def query_nvd_api(self, tech_name: str, tech_version: str) -> List[dict]:
        """Query NIST NVD API for vulnerabilities."""
        try:
            # NVD API endpoint
            base_url = "https://services.nvd.nist.gov/rest/json/cves/2.0"
            
            # Search parameters
            params = {
                'keywordSearch': tech_name,
                'resultsPerPage': 20,
                'startIndex': 0
            }
            
            response = requests.get(base_url, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            vulnerabilities = []
            
            for cve_item in data.get('vulnerabilities', []):
                cve = cve_item.get('cve', {})
                cve_id = cve.get('id', '')
                
                # Extract CVSS score
                cvss_score = 0
                severity = 'unknown'
                
                metrics = cve.get('metrics', {})
                if 'cvssMetricV31' in metrics:
                    cvss_data = metrics['cvssMetricV31'][0]['cvssData']
                    cvss_score = cvss_data.get('baseScore', 0)
                    severity = cvss_data.get('baseSeverity', 'unknown').lower()
                elif 'cvssMetricV30' in metrics:
                    cvss_data = metrics['cvssMetricV30'][0]['cvssData']
                    cvss_score = cvss_data.get('baseScore', 0)
                    severity = cvss_data.get('baseSeverity', 'unknown').lower()
                
                # Extract description
                descriptions = cve.get('descriptions', [])
                description = ''
                for desc in descriptions:
                    if desc.get('lang') == 'en':
                        description = desc.get('value', '')
                        break
                
                # Extract references
                references = []
                for ref in cve.get('references', []):
                    references.append(ref.get('url', ''))
                
                vulnerabilities.append({
                    'cve_id': cve_id,
                    'description': description,
                    'cvss_score': cvss_score,
                    'severity': severity,
                    'published_date': cve.get('published', ''),
                    'last_modified': cve.get('lastModified', ''),
                    'references': references,
                    'source': 'nvd',
                    'affected_technology': tech_name,
                    'affected_version': tech_version
                })
            
            return vulnerabilities
            
        except Exception as e:
            logger.error(f"Error querying NVD API: {str(e)}")
            return []
    
    def query_local_vuln_db(self, tech_name: str, tech_version: str) -> List[dict]:
        """Query local vulnerability database."""
        try:
            conn = sqlite3.connect('vulnerabilities.db')
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT * FROM cve_data 
                WHERE affected_products LIKE ? 
                ORDER BY cvss_score DESC
                LIMIT 10
            ''', (f'%{tech_name}%',))
            
            vulnerabilities = []
            for row in cursor.fetchall():
                vulnerabilities.append({
                    'cve_id': row[0],
                    'description': row[1],
                    'cvss_score': row[2],
                    'severity': row[3],
                    'published_date': row[4],
                    'affected_products': row[5],
                    'references': json.loads(row[6]) if row[6] else [],
                    'source': 'local_db',
                    'affected_technology': tech_name,
                    'affected_version': tech_version
                })
            
            conn.close()
            return vulnerabilities
            
        except Exception as e:
            logger.error(f"Error querying local vulnerability database: {str(e)}")
            return []
    
    def get_known_vulnerabilities(self, tech_name: str, tech_version: str) -> List[dict]:
        """Get known vulnerabilities for specific technologies."""
        known_vulns = {
            'apache': [
                {
                    'cve_id': 'CVE-2021-44228',
                    'description': 'Apache Log4j2 Remote Code Execution (Log4Shell)',
                    'cvss_score': 10.0,
                    'severity': 'critical',
                    'affected_versions': ['2.0-beta9', '2.15.0'],
                    'source': 'known_database'
                }
            ],
            'wordpress': [
                {
                    'cve_id': 'CVE-2022-21661',
                    'description': 'WordPress Core SQL Injection',
                    'cvss_score': 7.5,
                    'severity': 'high',
                    'affected_versions': ['<5.8.3'],
                    'source': 'known_database'
                }
            ],
            'nginx': [
                {
                    'cve_id': 'CVE-2021-23017',
                    'description': 'nginx DNS resolver off-by-one heap write',
                    'cvss_score': 8.1,
                    'severity': 'high',
                    'affected_versions': ['0.6.18-1.20.0'],
                    'source': 'known_database'
                }
            ]
        }
        
        return known_vulns.get(tech_name, [])
    
    def prioritize_vulnerabilities(self, vulnerabilities: List[dict]) -> List[dict]:
        """Prioritize vulnerabilities based on multiple factors."""
        try:
            for vuln in vulnerabilities:
                priority_score = 0
                
                # CVSS score weight (40%)
                cvss = vuln.get('cvss_score', 0)
                priority_score += cvss * 4
                
                # Exploit availability weight (30%)
                if self.has_known_exploit(vuln):
                    priority_score += 30
                
                # Age of vulnerability weight (20%)
                pub_date = vuln.get('published_date', '')
                if pub_date:
                    try:
                        pub_datetime = datetime.fromisoformat(pub_date.replace('Z', '+00:00'))
                        days_old = (datetime.now() - pub_datetime.replace(tzinfo=None)).days
                        if days_old < 30:  # Recent vulnerabilities are higher priority
                            priority_score += 20
                        elif days_old < 90:
                            priority_score += 15
                        elif days_old < 365:
                            priority_score += 10
                    except:
                        pass
                
                # Technology criticality weight (10%)
                tech_name = vuln.get('affected_technology', '')
                if tech_name in ['apache', 'nginx', 'ssh', 'ssl_certificate']:
                    priority_score += 10
                
                vuln['priority_score'] = priority_score
            
            # Sort by priority score
            return sorted(vulnerabilities, key=lambda x: x.get('priority_score', 0), reverse=True)
            
        except Exception as e:
            logger.error(f"Error prioritizing vulnerabilities: {str(e)}")
            return vulnerabilities
    
    def has_known_exploit(self, vuln: dict) -> bool:
        """Check if vulnerability has known exploits."""
        # This would integrate with exploit databases
        # For now, use heuristics based on CVSS and age
        cvss = vuln.get('cvss_score', 0)
        return cvss >= 7.0  # High/Critical vulnerabilities likely have exploits
    
    def calculate_risk_score(self, vulnerabilities: List[dict], tech_stack: List[dict]) -> int:
        """Calculate overall risk score."""
        try:
            if not vulnerabilities:
                return 0
            
            # Base score from vulnerabilities
            total_cvss = sum(v.get('cvss_score', 0) for v in vulnerabilities)
            avg_cvss = total_cvss / len(vulnerabilities)
            
            # Adjust for number of vulnerabilities
            vuln_count_factor = min(len(vulnerabilities) / 10, 2.0)  # Cap at 2x
            
            # Adjust for technology exposure
            exposure_factor = 1.0
            for tech in tech_stack:
                if tech.get('type') == 'service' and tech.get('port') in [21, 22, 23, 3389]:
                    exposure_factor += 0.2  # Risky services
            
            # Calculate final score (0-100)
            risk_score = min(100, int(avg_cvss * 10 * vuln_count_factor * exposure_factor))
            
            return risk_score
            
        except Exception as e:
            logger.error(f"Error calculating risk score: {str(e)}")
            return 0
    
    def generate_vuln_recommendations(self, vulnerabilities: List[dict], tech_stack: List[dict]) -> List[str]:
        """Generate vulnerability remediation recommendations."""
        recommendations = []
        
        try:
            if not vulnerabilities:
                recommendations.append("âœ… No critical vulnerabilities detected")
                return recommendations
            
            # Critical vulnerabilities
            critical_vulns = [v for v in vulnerabilities if v.get('cvss_score', 0) >= 9.0]
            if critical_vulns:
                recommendations.append(f"ðŸš¨ CRITICAL: {len(critical_vulns)} critical vulnerabilities require immediate patching")
                for vuln in critical_vulns[:3]:  # Top 3
                    recommendations.append(f"   â€¢ {vuln.get('cve_id', 'Unknown')}: {vuln.get('description', '')[:100]}...")
            
            # High severity vulnerabilities
            high_vulns = [v for v in vulnerabilities if 7.0 <= v.get('cvss_score', 0) < 9.0]
            if high_vulns:
                recommendations.append(f"âš ï¸ HIGH: {len(high_vulns)} high-severity vulnerabilities need attention")
            
            # Technology-specific recommendations
            tech_names = [t['name'] for t in tech_stack]
            
            if 'apache' in tech_names:
                recommendations.append("ðŸ”§ Update Apache to latest stable version")
                recommendations.append("ðŸ›¡ï¸ Configure security headers and disable unnecessary modules")
            
            if 'wordpress' in tech_names:
                recommendations.append("ðŸ”„ Keep WordPress core, themes, and plugins updated")
                recommendations.append("ðŸ”’ Implement strong authentication and limit login attempts")
            
            if 'ssh' in tech_names:
                recommendations.append("ðŸ”‘ Disable SSH password authentication, use key-based auth only")
                recommendations.append("ðŸšª Change default SSH port and implement fail2ban")
            
            # General recommendations
            recommendations.append("ðŸ“Š Implement vulnerability scanning in CI/CD pipeline")
            recommendations.append("ðŸ” Set up automated security monitoring and alerting")
            recommendations.append("ðŸ“‹ Create incident response plan for critical vulnerabilities")
            
            return recommendations
            
        except Exception as e:
            logger.error(f"Error generating recommendations: {str(e)}")
            return ["âŒ Unable to generate recommendations"]
    
    def assess_exploit_likelihood(self, vulnerabilities: List[dict]) -> dict:
        """Assess likelihood of exploitation."""
        try:
            if not vulnerabilities:
                return {'likelihood': 'low', 'score': 0}
            
            # Factors that increase exploit likelihood
            likelihood_score = 0
            
            # High CVSS scores
            high_cvss_count = sum(1 for v in vulnerabilities if v.get('cvss_score', 0) >= 7.0)
            likelihood_score += high_cvss_count * 10
            
            # Recent vulnerabilities
            recent_count = 0
            for vuln in vulnerabilities:
                pub_date = vuln.get('published_date', '')
                if pub_date:
                    try:
                        pub_datetime = datetime.fromisoformat(pub_date.replace('Z', '+00:00'))
                        days_old = (datetime.now() - pub_datetime.replace(tzinfo=None)).days
                        if days_old < 90:
                            recent_count += 1
                    except:
                        pass
            
            likelihood_score += recent_count * 5
            
            # Determine likelihood level
            if likelihood_score >= 50:
                likelihood = 'critical'
            elif likelihood_score >= 30:
                likelihood = 'high'
            elif likelihood_score >= 15:
                likelihood = 'medium'
            else:
                likelihood = 'low'
            
            return {
                'likelihood': likelihood,
                'score': min(100, likelihood_score),
                'factors': {
                    'high_cvss_vulnerabilities': high_cvss_count,
                    'recent_vulnerabilities': recent_count
                }
            }
            
        except Exception as e:
            logger.error(f"Error assessing exploit likelihood: {str(e)}")
            return {'likelihood': 'unknown', 'score': 0}
    
    def assess_compliance_impact(self, vulnerabilities: List[dict]) -> dict:
        """Assess compliance impact of vulnerabilities."""
        try:
            compliance_frameworks = {
                'PCI-DSS': 0,
                'HIPAA': 0,
                'SOX': 0,
                'GDPR': 0,
                'ISO27001': 0
            }
            
            # Critical vulnerabilities affect all compliance frameworks
            critical_count = sum(1 for v in vulnerabilities if v.get('cvss_score', 0) >= 9.0)
            high_count = sum(1 for v in vulnerabilities if 7.0 <= v.get('cvss_score', 0) < 9.0)
            
            for framework in compliance_frameworks:
                compliance_frameworks[framework] = critical_count * 20 + high_count * 10
            
            # Framework-specific impacts
            if any('encryption' in v.get('description', '').lower() for v in vulnerabilities):
                compliance_frameworks['PCI-DSS'] += 15
                compliance_frameworks['HIPAA'] += 15
                compliance_frameworks['GDPR'] += 10
            
            if any('authentication' in v.get('description', '').lower() for v in vulnerabilities):
                for framework in compliance_frameworks:
                    compliance_frameworks[framework] += 10
            
            # Determine overall compliance risk
            max_impact = max(compliance_frameworks.values())
            if max_impact >= 60:
                risk_level = 'critical'
            elif max_impact >= 40:
                risk_level = 'high'
            elif max_impact >= 20:
                risk_level = 'medium'
            else:
                risk_level = 'low'
            
            return {
                'overall_risk': risk_level,
                'framework_impacts': compliance_frameworks,
                'recommendations': self.get_compliance_recommendations(risk_level)
            }
            
        except Exception as e:
            logger.error(f"Error assessing compliance impact: {str(e)}")
            return {'overall_risk': 'unknown'}
    
    def get_compliance_recommendations(self, risk_level: str) -> List[str]:
        """Get compliance-specific recommendations."""
        if risk_level == 'critical':
            return [
                "ðŸš¨ Immediate remediation required for compliance",
                "ðŸ“‹ Document all vulnerabilities and remediation efforts",
                "ðŸ” Conduct emergency security assessment",
                "ðŸ“ž Notify compliance team and stakeholders"
            ]
        elif risk_level == 'high':
            return [
                "âš ï¸ Schedule remediation within compliance timeframes",
                "ðŸ“Š Update risk register and compliance documentation",
                "ðŸ”„ Review and update security policies"
            ]
        else:
            return [
                "âœ… Continue regular vulnerability management",
                "ðŸ“ˆ Monitor for new vulnerabilities"
            ]
    
    def deduplicate_tech_stack(self, tech_stack: List[dict]) -> List[dict]:
        """Remove duplicate technologies from stack."""
        seen = set()
        unique_stack = []
        
        for tech in tech_stack:
            key = f"{tech['name']}_{tech.get('version', 'unknown')}"
            if key not in seen:
                seen.add(key)
                unique_stack.append(tech)
        
        return unique_stack
    
    def store_scan_results(self, results: dict):
        """Store vulnerability scan results."""
        try:
            conn = sqlite3.connect('vulnerabilities.db')
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO vulnerability_scans 
                (domain, scan_timestamp, technologies, vulnerabilities, risk_score)
                VALUES (?, ?, ?, ?, ?)
            ''', (
                results['domain'],
                results['scan_timestamp'],
                json.dumps(results['tech_stack']),
                json.dumps(results['prioritized_vulnerabilities']),
                results['risk_score']
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"Error storing scan results: {str(e)}")

# Initialize global vulnerability correlator
vulnerability_correlator = VulnerabilityCorrelator()